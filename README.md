# AI Document Intelligence

A comprehensive AI-powered document intelligence system for automated invoice processing, text extraction, and data analysis.

## ğŸ¯ Project Overview

This project implements a complete pipeline for intelligent document processing with focus on invoice analysis:

- **OCR Processing**: Multiple OCR engines (PaddleOCR, Tesseract)
- **Data Extraction**: Automated field extraction from invoices
- **Error Analysis**: Comprehensive accuracy metrics and error tracking
- **Synthetic Data**: Realistic invoice generation for testing
- **Modular Design**: Easy to extend and customize

## ğŸ“… 30-Day Roadmap

### Week 1: Data Ownership & Infrastructure âœ…
- [x] Complete project structure setup
- [x] Dataset organization system
- [x] OCR baseline (PaddleOCR + Tesseract)
- [x] Synthetic invoice generator (200+ samples)
- [x] Error analysis framework
- [x] Unit tests and documentation

### Week 2: Preprocessing & Features (In Progress)
- [ ] Advanced image preprocessing pipeline
- [ ] Feature engineering for field extraction
- [ ] OCR optimization and parameter tuning
- [ ] Enhanced error pattern analysis
- [ ] Performance benchmarking

### Week 3: Model Training
- [ ] Custom field extraction model
- [ ] Layout analysis model
- [ ] Model evaluation and validation
- [ ] Hyperparameter optimization

### Week 4: Production & Deployment
- [ ] REST API development
- [ ] Web interface (Streamlit)
- [ ] Docker containerization
- [ ] Documentation and demo
- [ ] Performance optimization

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- Tesseract OCR
- 8GB RAM (minimum)

### Installation

```bash
# Clone repository
git clone https://github.com/NgoQuocTinh/ai-docs-intelligence.git
cd ai-docs-intelligence

# Run setup script
chmod +x scripts/setup_environment.sh
./scripts/setup_environment.sh

# Activate virtual environment
source venv/bin/activate
```

### Generate Synthetic Dataset

```bash
python scripts/generate_dataset.py --num-samples 200
```

### Run OCR Processing

```python
from src.ocr import OCREngine

engine = OCREngine(engine="paddle")
result = engine.process_image("dataset/raw/sample.png")
print(result["paddle"]["full_text"])
```

### Run Error Analysis

```python
from src.ocr import OCRErrorAnalyzer

analyzer = OCRErrorAnalyzer()
report = analyzer.generate_error_report(engine="paddle")
analyzer.save_report(report, "reports/error_report.json")
```

## ğŸ“ Project Structure

```
ai-docs-intelligence/
â”œâ”€â”€ configs/              # Configuration files
â”‚   â”œâ”€â”€ invoice_schema.json
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ dataset/              # Dataset storage
â”‚   â”œâ”€â”€ raw/             # Original documents
â”‚   â”œâ”€â”€ labels/          # Ground truth labels
â”‚   â”œâ”€â”€ ocr_text/        # OCR outputs
â”‚   â””â”€â”€ preprocessed/    # Processed images
â”œâ”€â”€ src/                 # Source code
â”‚   â”œâ”€â”€ data_collection/ # Dataset management
â”‚   â”‚   â”œâ”€â”€ collect_invoices.py
â”‚   â”‚   â””â”€â”€ generate_synthetic.py
â”‚   â”œâ”€â”€ ocr/            # OCR processing
â”‚   â”‚   â”œâ”€â”€ ocr_engine.py
â”‚   â”‚   â””â”€â”€ error_analysis.py
â”‚   â””â”€â”€ utils/          # Utilities
â”‚       â”œâ”€â”€ logger.py
â”‚       â””â”€â”€ file_utils.py
â”œâ”€â”€ notebooks/           # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_ocr_baseline.ipynb
â”‚   â””â”€â”€ 03_error_analysis.ipynb
â”œâ”€â”€ tests/              # Unit tests
â”‚   â”œâ”€â”€ test_data_collection.py
â”‚   â””â”€â”€ test_ocr_engine.py
â”œâ”€â”€ scripts/            # Automation scripts
â”‚   â”œâ”€â”€ setup_environment.sh
â”‚   â””â”€â”€ generate_dataset.py
â”œâ”€â”€ docs/               # Documentation
â”‚   â”œâ”€â”€ setup_guide.md
â”‚   â””â”€â”€ week1_report.md
â””â”€â”€ reports/            # Analysis reports
```

## ğŸ› ï¸ Tech Stack

### Core Technologies
- **Python 3.10+**: Primary language
- **PaddleOCR**: Advanced OCR engine
- **Tesseract**: Traditional OCR engine
- **OpenCV**: Image processing
- **Pillow**: Image manipulation

### ML/AI Frameworks
- **PyTorch**: Deep learning
- **Transformers**: NLP models
- **scikit-learn**: ML utilities

### Data & APIs
- **Pandas/NumPy**: Data processing
- **FastAPI**: REST API
- **Streamlit**: Web interface
- **SQLAlchemy**: Database ORM

### Testing & Quality
- **pytest**: Unit testing
- **Faker**: Synthetic data
- **pydantic**: Data validation

## ğŸ“Š Features

### Data Collection
- **DatasetOrganizer**: Manage document datasets with metadata
- **InvoiceGenerator**: Generate realistic synthetic invoices
- Supports multiple locales and noise levels

### OCR Processing
- **Dual Engine Support**: PaddleOCR and Tesseract
- **Batch Processing**: Process multiple documents efficiently
- **Structured Output**: JSON format with bounding boxes and confidence scores

### Error Analysis
- **Field-Level Accuracy**: Track accuracy for critical fields
- **String Similarity**: Fuzzy matching for extracted text
- **Comprehensive Reports**: Detailed error analysis with metrics

## ğŸ“ˆ Performance

### Dataset Metrics
- 200+ synthetic invoices generated
- Multiple noise levels for robustness testing
- Complete ground truth labels

### OCR Metrics
(Updated after baseline testing)
- Field extraction accuracy
- Processing speed
- Confidence scores

## ğŸ§ª Testing

Run unit tests:

```bash
# All tests
pytest tests/ -v

# With coverage
pytest tests/ --cov=src --cov-report=html

# Specific test
pytest tests/test_data_collection.py -v
```

Target: >70% code coverage

## ğŸ“š Documentation

- **Setup Guide**: [docs/setup_guide.md](docs/setup_guide.md)
- **Week 1 Report**: [docs/week1_report.md](docs/week1_report.md)
- **API Documentation**: Auto-generated from docstrings
- **Notebooks**: Interactive examples in `notebooks/`

## ğŸ¤ Contributing

This is a learning and development project. Contributions are welcome!

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“ Development Guidelines

- Follow PEP 8 style guide
- Add type hints to all functions
- Write comprehensive docstrings
- Include unit tests for new features
- Update documentation

## ğŸ” Troubleshooting

See [docs/setup_guide.md](docs/setup_guide.md) for common issues and solutions.

## ğŸ“„ License

This project is developed for educational and research purposes.

## ğŸ‘¥ Team

AI Document Intelligence Team

## ğŸ™ Acknowledgments

- PaddleOCR team for excellent OCR engine
- Tesseract OCR community
- Open source contributors

## ğŸ“¬ Contact

For questions or issues, please open a GitHub issue.

---

**Status**: Week 1 Complete âœ…  
**Last Updated**: January 2024  
**Version**: 0.1.0